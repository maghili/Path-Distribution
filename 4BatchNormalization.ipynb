{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Deep Learning Model with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take the input data and put it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Data = {'Peak':[],'Width': [], 'N': [] }\n",
    "Labels = []\n",
    "for i in range(2, 5):\n",
    "    Data = np.load('%d-D_Minkowski.npy'%i).tolist()\n",
    "    Input_Data['Peak']+=Data['peak']\n",
    "    Input_Data['Width']+=Data['width']\n",
    "    Input_Data['N']+=Data['N']\n",
    "    Labels += [i]*len(Data['peak'])\n",
    "df = pd.DataFrame.from_dict(Input_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "output_size = 3\n",
    "l1_nodes = 512\n",
    "l2_nodes = 512\n",
    "l3_nodes = 512\n",
    "learning_rate = .001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a deep leaning graph of the following shape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](batch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape = [None, input_size])\n",
    "\n",
    "#Batch Normalization 1\n",
    "with tf.variable_scope('batch1'):\n",
    "    batch1_out = tf.layers.batch_normalization(X)\n",
    " \n",
    "#layers\n",
    "with tf.variable_scope('layer1'):\n",
    "    weight = tf.get_variable(name = 'weight1', shape = [input_size, l1_nodes], \n",
    "                             initializer = tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(name = 'bias1', shape = [l1_nodes], initializer = tf.random_normal_initializer())\n",
    "    l1_output = tf.nn.relu(tf.matmul(batch1_out, weight)+biases)\n",
    "\n",
    "#Batch Normalization 2\n",
    "with tf.variable_scope('batch2'):\n",
    "    batch2_out = tf.layers.batch_normalization(l1_output)\n",
    "    \n",
    "with tf.variable_scope('layer2'):\n",
    "    weight = tf.get_variable(name = 'weight2', shape = [l1_nodes, l2_nodes], \n",
    "                             initializer = tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(name = 'bias2', shape = [l2_nodes], initializer = tf.random_normal_initializer())\n",
    "    l2_output = tf.nn.relu(tf.matmul(batch2_out, weight)+biases)\n",
    "\n",
    "#Batch Normalization 3\n",
    "with tf.variable_scope('batch3'):\n",
    "    batch3_out = tf.layers.batch_normalization(l2_output)    \n",
    "    \n",
    "with tf.variable_scope('layer3'):\n",
    "    weight = tf.get_variable(name = 'weight3', shape = [l2_nodes, l3_nodes], \n",
    "                             initializer = tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(name = 'bias3', shape = [l3_nodes], initializer = tf.random_normal_initializer())\n",
    "    l3_output = tf.nn.relu(tf.matmul(batch3_out, weight)+biases)\n",
    "\n",
    "#Batch Normalization 4\n",
    "with tf.variable_scope('batch4'):\n",
    "    batch4_out = tf.layers.batch_normalization(l3_output)       \n",
    "\n",
    "#Output\n",
    "with tf.variable_scope('output'):\n",
    "    weight = tf.get_variable(name = 'weight4', shape = [l3_nodes, output_size], \n",
    "                             initializer = tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(name = 'bias4', shape = [output_size], initializer = tf.random_normal_initializer())\n",
    "    predictions = tf.matmul(batch4_out, weight)+biases\n",
    "    \n",
    "#cost\n",
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.int32, shape = [None, output_size])\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = predictions, labels = Y))\n",
    "    #cost = tf.reduce_mean(keras.backend.sparse_categorical_crossentropy(Y, predictions, from_logits = True))\n",
    "    \n",
    "#training\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "#logging\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost', cost)\n",
    "    summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Manipulation\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.values, np.array(Labels), test_size = .1, random_state = 0)\n",
    "n_classes = 3\n",
    "y_cat_train = [[1 if i==y-2 else 0 for i in range(n_classes)] for y in y_train]\n",
    "y_cat_test = [[1 if i==y-2 else 0 for i in range(n_classes)] for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, X_test, y_train, y_test, n_epochs = 1000):\n",
    "    with tf.Session() as sess:\n",
    "        #initializing the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        training_writer = tf.summary.FileWriter('logs_4batch/training', sess.graph)\n",
    "        testing_writer = tf.summary.FileWriter('logs_4batch/testing', sess.graph)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            sess.run(optimizer, feed_dict = {X: X_train, Y: y_train})\n",
    "\n",
    "\n",
    "            print '\\r epoch: %d'%(epoch+1), \n",
    "\n",
    "            if(epoch+1) % (n_epochs/10) == 0:\n",
    "                [training_cost, training_summary] = sess.run([cost, summary], feed_dict = {\n",
    "                    X: X_train, Y: y_train})\n",
    "                [testing_cost, testing_summary] = sess.run([cost, summary], feed_dict = {\n",
    "                    X: X_test, Y: y_test})\n",
    "                print training_cost, testing_cost\n",
    "\n",
    "                training_writer.add_summary(training_summary, epoch)\n",
    "                testing_writer.add_summary(testing_summary, epoch)\n",
    "\n",
    "        print 'done!'\n",
    "\n",
    "        final_training_cost = sess.run(cost, feed_dict = {X: X_train, Y: y_train})\n",
    "        final_testing_cost = sess.run(cost, feed_dict = {X: X_test, Y: y_test})\n",
    "        print 'final training cost: ', training_cost, 'final testing cost: ', testing_cost\n",
    "\n",
    "        correct = tf.equal(tf.argmax(predictions, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        return accuracy.eval({X:np.array(X_test),Y:np.array(y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 100 2085.1104 2008.4938                             \n",
      " epoch: 200                                                   6572.543 6930.2886\n",
      " epoch: 300 4559.6064 3854.0845                              \n",
      " epoch: 400                                                   1105.857 902.0296\n",
      " epoch: 500 201.03676 127.407364                             \n",
      " epoch: 600                                                   25.391928 0.0\n",
      " epoch: 700 112.47049 69.6575                                \n",
      " epoch: 800                                                   21.806019 0.0\n",
      " epoch: 900 817.1382 921.26733                               \n",
      " epoch: 1000                                                  314.89578 370.89496\n",
      "done!\n",
      "final training cost:  314.89578 final testing cost:  370.89496\n",
      " epoch: 100                                                 1479.4156 1513.4423\n",
      " epoch: 200 2419.9336 2464.1577                              \n",
      " epoch: 300                                                   1826.3113 1668.4958\n",
      " epoch: 400 744.98895 820.1358                               \n",
      " epoch: 500                                                   398.43753 359.417\n",
      " epoch: 600 89.42769 119.95594                               \n",
      " epoch: 700                                                   406.69232 499.68842\n",
      " epoch: 800 24.710745 11.29493                               \n",
      " epoch: 900                                                   36.052097 52.528473\n",
      " epoch: 1000 17.511574 0.64944446                              \n",
      "done!\n",
      "final training cost:  17.511574 final testing cost:  0.64944446\n",
      " epoch: 100 4236.9077 4512.989                              \n",
      " epoch: 200 5592.549 5187.019                                 \n",
      " epoch: 300                                                    804.3187 773.82324\n",
      " epoch: 400 4417.443 4660.3135                                  \n",
      " epoch: 500                                                          646.8927 499.9293\n",
      " epoch: 600 380.14682 424.5585                               \n",
      " epoch: 700                                                    325.36035 361.35175\n",
      " epoch: 800 32.66292 0.0                                     \n",
      " epoch: 900                                                   89.871605 103.3475\n",
      " epoch: 1000 14.805587 0.0                                       \n",
      "done!\n",
      "final training cost:  14.805587 final testing cost:  0.0\n",
      " epoch: 100                                                 6978.952 7296.8066\n",
      " epoch: 200 16249.238 14520.769                              \n",
      " epoch: 300                                                          2021.2045 1804.6573\n",
      " epoch: 400 6410.9746 6122.9814                              \n",
      " epoch: 500                                                   288.93237 389.7618\n",
      " epoch: 600 1222.5385 1336.4764                              \n",
      " epoch: 700                                                   571.1268 749.87836\n",
      " epoch: 800 83.01125 78.79134                                \n",
      " epoch: 900                                                   61.36192 74.796585\n",
      " epoch: 1000                                                    53.442448 54.105953\n",
      "done!\n",
      "final training cost:  53.442448 final testing cost:  54.105953\n",
      " epoch: 100                                                    1305.1268 1343.6643\n",
      " epoch: 200 2522.3853 2728.2314                              \n",
      " epoch: 300                                                    288.2149 304.65137\n",
      " epoch: 400 244.01437 260.30402                              \n",
      " epoch: 500 403.7223 348.77072                                \n",
      " epoch: 600                                                   33.4197 56.02646\n",
      " epoch: 700 8.628866 7.9472845e-10                           \n",
      " epoch: 800                                                   7.59206 0.032847222\n",
      " epoch: 900 11.083757 4.7523265                              \n",
      " epoch: 1000                                                  11039.3955 9631.024\n",
      "done!\n",
      "final training cost:  11039.3955 final testing cost:  9631.024\n"
     ]
    }
   ],
   "source": [
    "a = [model(X_train, X_test, y_cat_train, y_cat_test) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9217777"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 100                                                1915.5895 1923.0067\n",
      " epoch: 200 2304.0083 2382.5986                              \n",
      " epoch: 300 2640.3196 2447.615                                \n",
      " epoch: 400                                                   1065.8821 985.0082\n",
      " epoch: 500 6052.9717 5511.4204                              \n",
      " epoch: 600 435.0472 417.61813                                \n",
      " epoch: 700                                                       106.02537 137.3419\n",
      " epoch: 800 68.53164 73.600945                                   \n",
      " epoch: 900                                                   67.05923 71.35722\n",
      " epoch: 1000 37.0286 21.198671                                                          \n",
      "done!\n",
      "final training cost:  37.0286 final testing cost:  21.198671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train, X_test, y_cat_train, y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the loss curve reduces pretty nicely:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](batched.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
